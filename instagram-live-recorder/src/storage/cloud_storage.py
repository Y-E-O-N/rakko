"""
í´ë¼ìš°ë“œ ì €ì¥ì†Œ ê´€ë¦¬ (Cloudflare R2 / S3 í˜¸í™˜)

Cloudflare R2ëŠ” S3 í˜¸í™˜ APIë¥¼ ì œê³µí•˜ë¯€ë¡œ boto3ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì €ì¥ ë¹„ìš©: $0.015/GB/ì›”
- ë‹¤ìš´ë¡œë“œ(egress) ë¹„ìš©: ë¬´ë£Œ!
- ì—° 200GB ì‚¬ìš© ì‹œ ì•½ $3/ë…„
"""
import os
import threading
from pathlib import Path
from typing import Optional, Dict, List, Callable
from datetime import datetime
from dataclasses import dataclass
import boto3
from boto3.s3.transfer import TransferConfig
from botocore.config import Config as BotoConfig
from botocore.exceptions import ClientError
from src.utils.logger import get_logger
from src.recorder.stream_recorder import RecordingTask

logger = get_logger()


@dataclass
class UploadProgress:
    """ì—…ë¡œë“œ ì§„í–‰ ìƒí™©"""
    filename: str
    total_bytes: int
    uploaded_bytes: int = 0
    
    @property
    def percentage(self) -> float:
        if self.total_bytes == 0:
            return 0
        return (self.uploaded_bytes / self.total_bytes) * 100


class ProgressCallback:
    """ì—…ë¡œë“œ ì§„í–‰ë¥  ì½œë°±"""
    
    def __init__(self, filename: str, total_size: int, callback: Optional[Callable] = None):
        self.filename = filename
        self.total_size = total_size
        self.uploaded = 0
        self.callback = callback
        self._lock = threading.Lock()
    
    def __call__(self, bytes_transferred: int):
        with self._lock:
            self.uploaded += bytes_transferred
            percentage = (self.uploaded / self.total_size) * 100 if self.total_size > 0 else 0
            
            if self.callback:
                self.callback(UploadProgress(
                    filename=self.filename,
                    total_bytes=self.total_size,
                    uploaded_bytes=self.uploaded
                ))
            
            # 10% ë‹¨ìœ„ë¡œ ë¡œê·¸ ì¶œë ¥
            if percentage % 10 < (bytes_transferred / self.total_size * 100):
                logger.debug(f"ì—…ë¡œë“œ ì§„í–‰: {self.filename} - {percentage:.1f}%")


class CloudStorage:
    """
    Cloudflare R2 ì €ì¥ì†Œ (S3 í˜¸í™˜)
    
    R2 íŠ¹ì§•:
    - S3 í˜¸í™˜ API
    - ì €ì¥: $0.015/GB/ì›”
    - ë‹¤ìš´ë¡œë“œ(egress): ë¬´ë£Œ
    - Class A ì‘ì—… (PUT, POST, LIST): $4.50/ë°±ë§Œ ìš”ì²­
    - Class B ì‘ì—… (GET): $0.36/ë°±ë§Œ ìš”ì²­
    """
    
    def __init__(
        self,
        account_id: str,
        access_key: str,
        secret_key: str,
        bucket_name: str,
        delete_after_upload: bool = False,
        public_url: str = ""
    ):
        self.account_id = account_id
        self.bucket_name = bucket_name
        self.delete_after_upload = delete_after_upload
        self.public_url = public_url  # ì»¤ìŠ¤í…€ ë„ë©”ì¸ ë˜ëŠ” R2.dev URL
        
        # R2 ì—”ë“œí¬ì¸íŠ¸
        self.endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
        
        # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client = boto3.client(
            's3',
            endpoint_url=self.endpoint_url,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key,
            config=BotoConfig(
                signature_version='s3v4',
                retries={
                    'max_attempts': 5,
                    'mode': 'adaptive'
                },
                connect_timeout=30,
                read_timeout=60
            )
        )
        
        # ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ ì„¤ì • (ëŒ€ìš©ëŸ‰ íŒŒì¼ìš©)
        # - 100MB ì´ìƒ íŒŒì¼ì€ ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ
        # - ê° íŒŒíŠ¸ í¬ê¸°: 50MB
        # - ìµœëŒ€ ë™ì‹œ ì „ì†¡: 5ê°œ
        self.transfer_config = TransferConfig(
            multipart_threshold=100 * 1024 * 1024,  # 100MB
            multipart_chunksize=50 * 1024 * 1024,   # 50MB
            max_concurrency=5,
            use_threads=True
        )
        
        # ì—…ë¡œë“œ ì½œë°±
        self._upload_callbacks: List[Callable] = []
        
        self._verify_bucket()
    
    def _verify_bucket(self):
        """ë²„í‚· ì¡´ì¬ í™•ì¸"""
        try:
            self.client.head_bucket(Bucket=self.bucket_name)
            logger.info(f"R2 ë²„í‚· ì—°ê²° ì„±ê³µ: {self.bucket_name}")
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            if error_code == '404':
                logger.warning(f"ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤: {self.bucket_name}")
                self._create_bucket()
            elif error_code == '403':
                logger.error("ë²„í‚· ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. API í† í° ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
                raise
            else:
                logger.error(f"ë²„í‚· í™•ì¸ ì‹¤íŒ¨: {e}")
                raise
    
    def _create_bucket(self):
        """ë²„í‚· ìƒì„±"""
        try:
            self.client.create_bucket(Bucket=self.bucket_name)
            logger.info(f"R2 ë²„í‚· ìƒì„±ë¨: {self.bucket_name}")
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            if error_code == 'BucketAlreadyOwnedByYou':
                logger.info(f"ë²„í‚·ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {self.bucket_name}")
            else:
                logger.error(f"ë²„í‚· ìƒì„± ì‹¤íŒ¨: {e}")
                raise
    
    def on_upload_progress(self, callback: Callable):
        """ì—…ë¡œë“œ ì§„í–‰ë¥  ì½œë°± ë“±ë¡"""
        self._upload_callbacks.append(callback)
    
    def upload_file(
        self,
        local_path: Path,
        remote_path: Optional[str] = None,
        metadata: Optional[Dict] = None,
        content_type: Optional[str] = None
    ) -> bool:
        """
        íŒŒì¼ ì—…ë¡œë“œ
        
        Args:
            local_path: ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
            remote_path: ì›ê²© ê²½ë¡œ (Noneì´ë©´ íŒŒì¼ëª… ì‚¬ìš©)
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            content_type: MIME íƒ€ì… (Noneì´ë©´ ìë™ ê°ì§€)
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        local_path = Path(local_path)
        
        if not local_path.exists():
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {local_path}")
            return False
        
        if remote_path is None:
            remote_path = local_path.name
        
        # íŒŒì¼ í¬ê¸°
        file_size = local_path.stat().st_size
        
        try:
            extra_args = {}
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            if metadata:
                extra_args['Metadata'] = {
                    k: str(v)[:1024] for k, v in metadata.items()  # R2 ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ
                }
            
            # Content-Type ì„¤ì •
            if content_type:
                extra_args['ContentType'] = content_type
            else:
                suffix = local_path.suffix.lower()
                content_types = {
                    '.mp4': 'video/mp4',
                    '.mkv': 'video/x-matroska',
                    '.webm': 'video/webm',
                    '.ts': 'video/mp2t',
                    '.m4a': 'audio/mp4',
                    '.jpg': 'image/jpeg',
                    '.jpeg': 'image/jpeg',
                    '.png': 'image/png'
                }
                if suffix in content_types:
                    extra_args['ContentType'] = content_types[suffix]
            
            # ì—…ë¡œë“œ ì‹œì‘
            logger.info(
                f"â˜ï¸ R2 ì—…ë¡œë“œ ì‹œì‘: {local_path.name} "
                f"({self._format_size(file_size)}) -> {remote_path}"
            )
            
            # ì§„í–‰ë¥  ì½œë°± ì„¤ì •
            progress_callback = None
            if self._upload_callbacks:
                def combined_callback(progress: UploadProgress):
                    for cb in self._upload_callbacks:
                        cb(progress)
                progress_callback = ProgressCallback(
                    local_path.name, 
                    file_size, 
                    combined_callback
                )
            
            # ì—…ë¡œë“œ (ë©€í‹°íŒŒíŠ¸ ìë™ ì²˜ë¦¬)
            self.client.upload_file(
                str(local_path),
                self.bucket_name,
                remote_path,
                ExtraArgs=extra_args if extra_args else None,
                Config=self.transfer_config,
                Callback=progress_callback
            )
            
            logger.info(f"âœ… R2 ì—…ë¡œë“œ ì™„ë£Œ: {remote_path}")
            
            # ë¡œì»¬ íŒŒì¼ ì‚­ì œ ì˜µì…˜
            if self.delete_after_upload:
                local_path.unlink()
                logger.info(f"ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì‚­ì œë¨: {local_path}")
            
            return True
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            error_msg = e.response.get('Error', {}).get('Message', str(e))
            
            if error_code == 'EntityTooLarge':
                logger.error(f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (R2 ìµœëŒ€: 5TB): {local_path}")
            elif error_code == 'AccessDenied':
                logger.error("ì—…ë¡œë“œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. API í† í°ì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                logger.error(f"R2 ì—…ë¡œë“œ ì‹¤íŒ¨: {error_code} - {error_msg}")
            return False
            
        except Exception as e:
            logger.error(f"R2 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def upload_recording(self, task: RecordingTask) -> bool:
        """ë…¹í™” íŒŒì¼ ì—…ë¡œë“œ"""
        if not task.output_path.exists():
            logger.warning(f"ë…¹í™” íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {task.output_path}")
            return False
        
        # ì›ê²© ê²½ë¡œ: username/YYYY-MM/filename
        # ì›”ë³„ë¡œ í´ë” ì •ë¦¬
        month_folder = task.started_at.strftime('%Y-%m') if task.started_at else 'unknown'
        remote_path = f"{task.broadcast.username}/{month_folder}/{task.output_path.name}"
        
        # ë©”íƒ€ë°ì´í„° (S3 í˜¸í™˜ - ASCII ì•ˆì „í•˜ê²Œ ì¸ì½”ë”©)
        # R2/S3 ë©”íƒ€ë°ì´í„°ëŠ” ASCIIë§Œ í—ˆìš©í•˜ë¯€ë¡œ URL ì¸ì½”ë”© ì‚¬ìš©
        import urllib.parse
        
        def safe_metadata(value: str, max_length: int = 200) -> str:
            """ë©”íƒ€ë°ì´í„° ê°’ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
            if not value:
                return ""
            # ASCIIê°€ ì•„ë‹Œ ë¬¸ìë¥¼ URL ì¸ì½”ë”©
            encoded = urllib.parse.quote(str(value)[:max_length], safe='')
            # ìµœëŒ€ ê¸¸ì´ ì œí•œ (ì¸ì½”ë”© í›„)
            return encoded[:500]
        
        metadata = {
            'username': safe_metadata(task.broadcast.username),
            'broadcast_id': safe_metadata(task.broadcast.broadcast_id),
            'display_name': safe_metadata(task.broadcast.display_name),
            'recorded_at': task.started_at.isoformat() if task.started_at else '',
            'ended_at': task.ended_at.isoformat() if task.ended_at else '',
            'duration_seconds': str(
                int((task.ended_at - task.started_at).total_seconds())
                if task.started_at and task.ended_at else 0
            ),
            'title': safe_metadata(task.broadcast.title),
            'viewer_count': str(task.broadcast.viewer_count)
        }
        
        return self.upload_file(task.output_path, remote_path, metadata)
    
    def download_file(
        self,
        remote_path: str,
        local_path: Path
    ) -> bool:
        """
        íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        
        Args:
            remote_path: R2 ê²½ë¡œ
            local_path: ì €ì¥í•  ë¡œì»¬ ê²½ë¡œ
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            local_path = Path(local_path)
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"R2 ë‹¤ìš´ë¡œë“œ: {remote_path} -> {local_path}")
            
            self.client.download_file(
                self.bucket_name,
                remote_path,
                str(local_path),
                Config=self.transfer_config
            )
            
            logger.info(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
            return True
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            if error_code == '404' or error_code == 'NoSuchKey':
                logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {remote_path}")
            else:
                logger.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def list_files(
        self,
        prefix: str = "",
        max_keys: int = 1000
    ) -> List[Dict]:
        """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        try:
            files = []
            continuation_token = None
            
            while True:
                params = {
                    'Bucket': self.bucket_name,
                    'Prefix': prefix,
                    'MaxKeys': min(max_keys - len(files), 1000)
                }
                
                if continuation_token:
                    params['ContinuationToken'] = continuation_token
                
                response = self.client.list_objects_v2(**params)
                
                for obj in response.get('Contents', []):
                    files.append({
                        'key': obj['Key'],
                        'size': obj['Size'],
                        'size_formatted': self._format_size(obj['Size']),
                        'last_modified': obj['LastModified'],
                        'etag': obj.get('ETag', '').strip('"')
                    })
                
                # í˜ì´ì§€ë„¤ì´ì…˜
                if response.get('IsTruncated') and len(files) < max_keys:
                    continuation_token = response.get('NextContinuationToken')
                else:
                    break
            
            return files
            
        except ClientError as e:
            logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def list_recordings(self, username: str = "") -> List[Dict]:
        """
        ë…¹í™” íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        
        Args:
            username: íŠ¹ì • ìœ ì €ì˜ ë…¹í™”ë§Œ ì¡°íšŒ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ì „ì²´)
        
        Returns:
            ë…¹í™” íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        prefix = f"{username}/" if username else ""
        files = self.list_files(prefix=prefix)
        
        # ë¹„ë””ì˜¤ íŒŒì¼ë§Œ í•„í„°ë§
        video_extensions = ('.mp4', '.mkv', '.webm', '.ts')
        return [f for f in files if f['key'].lower().endswith(video_extensions)]
    
    def get_file_info(self, remote_path: str) -> Optional[Dict]:
        """íŒŒì¼ ì •ë³´ ë° ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        try:
            response = self.client.head_object(
                Bucket=self.bucket_name,
                Key=remote_path
            )
            
            return {
                'key': remote_path,
                'size': response['ContentLength'],
                'size_formatted': self._format_size(response['ContentLength']),
                'content_type': response.get('ContentType', ''),
                'last_modified': response.get('LastModified'),
                'metadata': response.get('Metadata', {}),
                'etag': response.get('ETag', '').strip('"')
            }
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            if error_code == '404':
                return None
            logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def get_download_url(self, remote_path: str, expires_in: int = 3600) -> str:
        """
        ë‹¤ìš´ë¡œë“œ URL ìƒì„± (Presigned URL)
        
        Args:
            remote_path: R2 ê²½ë¡œ
            expires_in: URL ìœ íš¨ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ 1ì‹œê°„, ìµœëŒ€ 7ì¼)
        
        Returns:
            Presigned URL
        """
        try:
            # R2ëŠ” ìµœëŒ€ 7ì¼ê¹Œì§€ ì§€ì›
            expires_in = min(expires_in, 7 * 24 * 3600)
            
            url = self.client.generate_presigned_url(
                'get_object',
                Params={
                    'Bucket': self.bucket_name,
                    'Key': remote_path
                },
                ExpiresIn=expires_in
            )
            return url
        except ClientError as e:
            logger.error(f"URL ìƒì„± ì‹¤íŒ¨: {e}")
            return ""
    
    def get_public_url(self, remote_path: str) -> str:
        """
        ê³µê°œ URL ë°˜í™˜ (í¼ë¸”ë¦­ ë²„í‚· ë˜ëŠ” ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì„¤ì • ì‹œ)
        
        Args:
            remote_path: R2 ê²½ë¡œ
        
        Returns:
            ê³µê°œ URL
        """
        if self.public_url:
            return f"{self.public_url.rstrip('/')}/{remote_path}"
        return ""
    
    def delete_file(self, remote_path: str) -> bool:
        """íŒŒì¼ ì‚­ì œ"""
        try:
            self.client.delete_object(
                Bucket=self.bucket_name,
                Key=remote_path
            )
            logger.info(f"R2 íŒŒì¼ ì‚­ì œë¨: {remote_path}")
            return True
        except ClientError as e:
            logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def delete_files(self, remote_paths: List[str]) -> int:
        """
        ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì‚­ì œ
        
        Args:
            remote_paths: ì‚­ì œí•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì‚­ì œëœ íŒŒì¼ ìˆ˜
        """
        if not remote_paths:
            return 0
        
        try:
            # R2ëŠ” í•œ ë²ˆì— ìµœëŒ€ 1000ê°œ ì‚­ì œ ê°€ëŠ¥
            deleted_count = 0
            
            for i in range(0, len(remote_paths), 1000):
                batch = remote_paths[i:i + 1000]
                
                response = self.client.delete_objects(
                    Bucket=self.bucket_name,
                    Delete={
                        'Objects': [{'Key': key} for key in batch],
                        'Quiet': True
                    }
                )
                
                errors = response.get('Errors', [])
                deleted_count += len(batch) - len(errors)
                
                for error in errors:
                    logger.warning(f"ì‚­ì œ ì‹¤íŒ¨: {error['Key']} - {error['Message']}")
            
            logger.info(f"R2 íŒŒì¼ {deleted_count}ê°œ ì‚­ì œë¨")
            return deleted_count
            
        except ClientError as e:
            logger.error(f"ì¼ê´„ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_storage_usage(self) -> Dict:
        """ì €ì¥ì†Œ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            files = self.list_files(max_keys=10000)
            total_size = sum(f['size'] for f in files)
            
            # ìœ ì €ë³„ í†µê³„
            user_stats = {}
            for f in files:
                parts = f['key'].split('/')
                if len(parts) > 0:
                    username = parts[0]
                    if username not in user_stats:
                        user_stats[username] = {'count': 0, 'size': 0}
                    user_stats[username]['count'] += 1
                    user_stats[username]['size'] += f['size']
            
            # ì›”ë³„ ë¹„ìš© ì¶”ì • ($0.015/GB)
            monthly_cost = (total_size / (1024 ** 3)) * 0.015
            
            return {
                'file_count': len(files),
                'total_size_bytes': total_size,
                'total_size_formatted': self._format_size(total_size),
                'estimated_monthly_cost': f"${monthly_cost:.2f}",
                'user_stats': {
                    k: {
                        'count': v['count'],
                        'size_formatted': self._format_size(v['size'])
                    }
                    for k, v in user_stats.items()
                }
            }
        except Exception as e:
            logger.error(f"ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'file_count': 0,
                'total_size_bytes': 0,
                'total_size_formatted': '0 B',
                'estimated_monthly_cost': '$0.00',
                'user_stats': {}
            }
    
    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            self.client.head_bucket(Bucket=self.bucket_name)
            logger.info("R2 ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"R2 ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _format_size(self, size_bytes: int) -> str:
        """ë°”ì´íŠ¸ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"


def create_cloud_storage(config) -> Optional[CloudStorage]:
    """ì„¤ì •ì—ì„œ CloudStorage ìƒì„±"""
    if not config.cloud_enabled:
        logger.info("í´ë¼ìš°ë“œ ì €ì¥ì†Œê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        return None
    
    if config.cloud_provider != "r2":
        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í´ë¼ìš°ë“œ ì œê³µì: {config.cloud_provider}")
        return None
    
    if not all([config.r2_account_id, config.r2_access_key, config.r2_secret_key]):
        logger.warning(
            "R2 ì„¤ì •ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. í•„ìš”í•œ ì„¤ì •:\n"
            "  - r2.account_id\n"
            "  - r2.access_key_id\n"
            "  - r2.secret_access_key\n"
            "í´ë¼ìš°ë“œ ì €ì¥ì†Œê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤."
        )
        return None
    
    try:
        storage = CloudStorage(
            account_id=config.r2_account_id,
            access_key=config.r2_access_key,
            secret_key=config.r2_secret_key,
            bucket_name=config.r2_bucket,
            delete_after_upload=config.delete_after_upload,
            public_url=getattr(config, 'r2_public_url', '')
        )
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not storage.test_connection():
            logger.warning("R2 ì—°ê²° ì‹¤íŒ¨. ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            return None
        
        return storage
        
    except Exception as e:
        logger.error(f"CloudStorage ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
